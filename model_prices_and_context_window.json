{
  "claude-3-5-haiku-20241022": {
    "cache_creation_input_token_cost": 1e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 8e-08,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 8e-07,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 4e-06,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 264
  },
  "claude-3-5-haiku-latest": {
    "cache_creation_input_token_cost": 1.25e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 1e-07,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 1e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 5e-06,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 264
  },
  "claude-3-5-sonnet-20240620": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 3e-07,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 3e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-5-sonnet-20241022": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 3e-07,
    "deprecation_date": "2025-10-01",
    "input_cost_per_token": 3e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-5-sonnet-latest": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 3e-07,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 3e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-7-sonnet-20250219": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 3e-07,
    "deprecation_date": "2026-02-19",
    "input_cost_per_token": 3e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-7-sonnet-latest": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 3e-07,
    "deprecation_date": "2025-06-01",
    "input_cost_per_token": 3e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-3-haiku-20240307": {
    "cache_creation_input_token_cost": 3e-07,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 3e-08,
    "input_cost_per_token": 2.5e-07,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.25e-06,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 264
  },
  "claude-3-opus-20240229": {
    "cache_creation_input_token_cost": 1.875e-05,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 1.5e-06,
    "deprecation_date": "2026-05-01",
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 7.5e-05,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 395
  },
  "claude-3-opus-latest": {
    "cache_creation_input_token_cost": 1.875e-05,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_read_input_token_cost": 1.5e-06,
    "deprecation_date": "2025-03-01",
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 7.5e-05,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 395
  },
  "claude-4-opus-20250514": {
    "cache_creation_input_token_cost": 1.875e-05,
    "cache_creation_input_token_cost_above_1hr": 3e-05,
    "cache_read_input_token_cost": 1.5e-06,
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 7.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-4-sonnet-20250514": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
    "cache_read_input_token_cost": 3e-07,
    "cache_read_input_token_cost_above_200k_tokens": 6e-07,
    "input_cost_per_token": 3e-06,
    "input_cost_per_token_above_200k_tokens": 6e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "output_cost_per_token_above_200k_tokens": 2.25e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-haiku-4-5": {
    "cache_creation_input_token_cost": 1.25e-06,
    "cache_creation_input_token_cost_above_1hr": 2e-06,
    "cache_read_input_token_cost": 1e-07,
    "input_cost_per_token": 1e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 5e-06,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "claude-haiku-4-5-20251001": {
    "cache_creation_input_token_cost": 1.25e-06,
    "cache_creation_input_token_cost_above_1hr": 2e-06,
    "cache_read_input_token_cost": 1e-07,
    "input_cost_per_token": 1e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 5e-06,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "claude-opus-4-1": {
    "cache_creation_input_token_cost": 1.875e-05,
    "cache_creation_input_token_cost_above_1hr": 3e-05,
    "cache_read_input_token_cost": 1.5e-06,
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 7.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-1-20250805": {
    "cache_creation_input_token_cost": 1.875e-05,
    "cache_creation_input_token_cost_above_1hr": 3e-05,
    "cache_read_input_token_cost": 1.5e-06,
    "deprecation_date": "2026-08-05",
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 7.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-20250514": {
    "cache_creation_input_token_cost": 1.875e-05,
    "cache_creation_input_token_cost_above_1hr": 3e-05,
    "cache_read_input_token_cost": 1.5e-06,
    "deprecation_date": "2026-05-14",
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 32000,
    "max_tokens": 32000,
    "mode": "chat",
    "output_cost_per_token": 7.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-5": {
    "cache_creation_input_token_cost": 6.25e-06,
    "cache_creation_input_token_cost_above_1hr": 1e-05,
    "cache_read_input_token_cost": 5e-07,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 2.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-5-20251101": {
    "cache_creation_input_token_cost": 6.25e-06,
    "cache_creation_input_token_cost_above_1hr": 1e-05,
    "cache_read_input_token_cost": 5e-07,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 2.5e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-opus-4-6": {
    "cache_creation_input_token_cost": 6.25e-06,
    "cache_creation_input_token_cost_above_1hr": 1e-05,
    "cache_creation_input_token_cost_above_200k_tokens": 1.25e-05,
    "cache_read_input_token_cost": 5e-07,
    "cache_read_input_token_cost_above_200k_tokens": 1e-06,
    "input_cost_per_token": 5e-06,
    "input_cost_per_token_above_200k_tokens": 1e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2.5e-05,
    "output_cost_per_token_above_200k_tokens": 3.75e-05,
    "provider_specific_entry": {
      "fast": 6.0,
      "us": 1.1
    },
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-opus-4-6-20260205": {
    "cache_creation_input_token_cost": 6.25e-06,
    "cache_creation_input_token_cost_above_1hr": 1e-05,
    "cache_creation_input_token_cost_above_200k_tokens": 1.25e-05,
    "cache_read_input_token_cost": 5e-07,
    "cache_read_input_token_cost_above_200k_tokens": 1e-06,
    "input_cost_per_token": 5e-06,
    "input_cost_per_token_above_200k_tokens": 1e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2.5e-05,
    "output_cost_per_token_above_200k_tokens": 3.75e-05,
    "provider_specific_entry": {
      "fast": 6.0,
      "us": 1.1
    },
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-opus-4-6-thinking": {
    "cache_creation_input_token_cost": 6.25e-06,
    "cache_creation_input_token_cost_above_1hr": 1e-05,
    "cache_creation_input_token_cost_above_200k_tokens": 1.25e-05,
    "cache_read_input_token_cost": 5e-07,
    "cache_read_input_token_cost_above_200k_tokens": 1e-06,
    "input_cost_per_token": 5e-06,
    "input_cost_per_token_above_200k_tokens": 1e-05,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2.5e-05,
    "output_cost_per_token_above_200k_tokens": 3.75e-05,
    "provider_specific_entry": {
      "fast": 6.0,
      "us": 1.1
    },
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": false,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-sonnet-4-20250514": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
    "cache_read_input_token_cost": 3e-07,
    "cache_read_input_token_cost_above_200k_tokens": 6e-07,
    "deprecation_date": "2026-05-14",
    "input_cost_per_token": 3e-06,
    "input_cost_per_token_above_200k_tokens": 6e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 1000000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "output_cost_per_token_above_200k_tokens": 2.25e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-sonnet-4-5": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
    "cache_read_input_token_cost": 3e-07,
    "cache_read_input_token_cost_above_200k_tokens": 6e-07,
    "input_cost_per_token": 3e-06,
    "input_cost_per_token_above_200k_tokens": 6e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "output_cost_per_token_above_200k_tokens": 2.25e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-sonnet-4-5-20250929": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
    "cache_read_input_token_cost": 3e-07,
    "cache_read_input_token_cost_above_200k_tokens": 6e-07,
    "input_cost_per_token": 3e-06,
    "input_cost_per_token_above_200k_tokens": 6e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "output_cost_per_token_above_200k_tokens": 2.25e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tool_use_system_prompt_tokens": 346
  },
  "claude-sonnet-4-5-20250929-v1:0": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
    "cache_read_input_token_cost": 3e-07,
    "cache_read_input_token_cost_above_200k_tokens": 6e-07,
    "input_cost_per_token": 3e-06,
    "input_cost_per_token_above_200k_tokens": 6e-06,
    "litellm_provider": "bedrock",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "output_cost_per_token_above_200k_tokens": 2.25e-05,
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 159
  },
  "claude-sonnet-4-6": {
    "cache_creation_input_token_cost": 3.75e-06,
    "cache_creation_input_token_cost_above_1hr": 6e-06,
    "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
    "cache_read_input_token_cost": 3e-07,
    "cache_read_input_token_cost_above_200k_tokens": 6e-07,
    "input_cost_per_token": 3e-06,
    "input_cost_per_token_above_200k_tokens": 6e-06,
    "litellm_provider": "anthropic",
    "max_input_tokens": 200000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "output_cost_per_token_above_200k_tokens": 2.25e-05,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.01,
      "search_context_size_low": 0.01,
      "search_context_size_medium": 0.01
    },
    "supports_assistant_prefill": true,
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "tool_use_system_prompt_tokens": 346
  },
  "deepseek-chat": {
    "cache_read_input_token_cost": 2.8e-08,
    "input_cost_per_token": 2.8e-07,
    "litellm_provider": "deepseek",
    "max_input_tokens": 131072,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 4.2e-07,
    "source": "https://api-docs.deepseek.com/quick_start/pricing",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "deepseek-reasoner": {
    "cache_read_input_token_cost": 2.8e-08,
    "input_cost_per_token": 2.8e-07,
    "litellm_provider": "deepseek",
    "max_input_tokens": 131072,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 4.2e-07,
    "source": "https://api-docs.deepseek.com/quick_start/pricing",
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false
  },
  "deepseek-v3-2-251201": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "volcengine",
    "max_input_tokens": 98304,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 0.0,
    "supports_assistant_prefill": true,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_tool_choice": true
  },
  "gemini-1.0-pro": {
    "input_cost_per_character": 1.25e-07,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "input_cost_per_video_per_second": 0.002,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 3.75e-07,
    "output_cost_per_token": 1.5e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-1.0-pro-001": {
    "deprecation_date": "2025-04-09",
    "input_cost_per_character": 1.25e-07,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "input_cost_per_video_per_second": 0.002,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 3.75e-07,
    "output_cost_per_token": 1.5e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-1.0-pro-002": {
    "deprecation_date": "2025-04-09",
    "input_cost_per_character": 1.25e-07,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "input_cost_per_video_per_second": 0.002,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 3.75e-07,
    "output_cost_per_token": 1.5e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-1.0-pro-vision": {
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "litellm_provider": "vertex_ai-vision-models",
    "max_images_per_prompt": 16,
    "max_input_tokens": 16384,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "max_video_length": 2,
    "max_videos_per_prompt": 1,
    "mode": "chat",
    "output_cost_per_token": 1.5e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.0-pro-vision-001": {
    "deprecation_date": "2025-04-09",
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "litellm_provider": "vertex_ai-vision-models",
    "max_images_per_prompt": 16,
    "max_input_tokens": 16384,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "max_video_length": 2,
    "max_videos_per_prompt": 1,
    "mode": "chat",
    "output_cost_per_token": 1.5e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.0-ultra": {
    "input_cost_per_character": 1.25e-07,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "input_cost_per_video_per_second": 0.002,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 8192,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_character": 3.75e-07,
    "output_cost_per_token": 1.5e-06,
    "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-1.0-ultra-001": {
    "input_cost_per_character": 1.25e-07,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "input_cost_per_video_per_second": 0.002,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 8192,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "mode": "chat",
    "output_cost_per_character": 3.75e-07,
    "output_cost_per_token": 1.5e-06,
    "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-1.5-flash": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 2e-06,
    "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
    "input_cost_per_character": 1.875e-08,
    "input_cost_per_character_above_128k_tokens": 2.5e-07,
    "input_cost_per_image": 2e-05,
    "input_cost_per_image_above_128k_tokens": 4e-05,
    "input_cost_per_token": 7.5e-08,
    "input_cost_per_token_above_128k_tokens": 1e-06,
    "input_cost_per_video_per_second": 2e-05,
    "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 7.5e-08,
    "output_cost_per_character_above_128k_tokens": 1.5e-07,
    "output_cost_per_token": 3e-07,
    "output_cost_per_token_above_128k_tokens": 6e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-flash-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_audio_per_second": 2e-06,
    "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
    "input_cost_per_character": 1.875e-08,
    "input_cost_per_character_above_128k_tokens": 2.5e-07,
    "input_cost_per_image": 2e-05,
    "input_cost_per_image_above_128k_tokens": 4e-05,
    "input_cost_per_token": 7.5e-08,
    "input_cost_per_token_above_128k_tokens": 1e-06,
    "input_cost_per_video_per_second": 2e-05,
    "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 7.5e-08,
    "output_cost_per_character_above_128k_tokens": 1.5e-07,
    "output_cost_per_token": 3e-07,
    "output_cost_per_token_above_128k_tokens": 6e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-flash-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_audio_per_second": 2e-06,
    "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
    "input_cost_per_character": 1.875e-08,
    "input_cost_per_character_above_128k_tokens": 2.5e-07,
    "input_cost_per_image": 2e-05,
    "input_cost_per_image_above_128k_tokens": 4e-05,
    "input_cost_per_token": 7.5e-08,
    "input_cost_per_token_above_128k_tokens": 1e-06,
    "input_cost_per_video_per_second": 2e-05,
    "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 7.5e-08,
    "output_cost_per_character_above_128k_tokens": 1.5e-07,
    "output_cost_per_token": 3e-07,
    "output_cost_per_token_above_128k_tokens": 6e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-flash-exp-0827": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 2e-06,
    "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
    "input_cost_per_character": 1.875e-08,
    "input_cost_per_character_above_128k_tokens": 2.5e-07,
    "input_cost_per_image": 2e-05,
    "input_cost_per_image_above_128k_tokens": 4e-05,
    "input_cost_per_token": 4.688e-09,
    "input_cost_per_token_above_128k_tokens": 1e-06,
    "input_cost_per_video_per_second": 2e-05,
    "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 1.875e-08,
    "output_cost_per_character_above_128k_tokens": 3.75e-08,
    "output_cost_per_token": 4.6875e-09,
    "output_cost_per_token_above_128k_tokens": 9.375e-09,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-flash-preview-0514": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 2e-06,
    "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
    "input_cost_per_character": 1.875e-08,
    "input_cost_per_character_above_128k_tokens": 2.5e-07,
    "input_cost_per_image": 2e-05,
    "input_cost_per_image_above_128k_tokens": 4e-05,
    "input_cost_per_token": 7.5e-08,
    "input_cost_per_token_above_128k_tokens": 1e-06,
    "input_cost_per_video_per_second": 2e-05,
    "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 1.875e-08,
    "output_cost_per_character_above_128k_tokens": 3.75e-08,
    "output_cost_per_token": 4.6875e-09,
    "output_cost_per_token_above_128k_tokens": 9.375e-09,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-pro": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 3.125e-05,
    "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
    "input_cost_per_character": 3.125e-07,
    "input_cost_per_character_above_128k_tokens": 6.25e-07,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_128k_tokens": 2.5e-06,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 1.25e-06,
    "output_cost_per_character_above_128k_tokens": 2.5e-06,
    "output_cost_per_token": 5e-06,
    "output_cost_per_token_above_128k_tokens": 1e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-pro-001": {
    "deprecation_date": "2025-05-24",
    "input_cost_per_audio_per_second": 3.125e-05,
    "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
    "input_cost_per_character": 3.125e-07,
    "input_cost_per_character_above_128k_tokens": 6.25e-07,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_128k_tokens": 2.5e-06,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 1.25e-06,
    "output_cost_per_character_above_128k_tokens": 2.5e-06,
    "output_cost_per_token": 5e-06,
    "output_cost_per_token_above_128k_tokens": 1e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-pro-002": {
    "deprecation_date": "2025-09-24",
    "input_cost_per_audio_per_second": 3.125e-05,
    "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
    "input_cost_per_character": 3.125e-07,
    "input_cost_per_character_above_128k_tokens": 6.25e-07,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_128k_tokens": 2.5e-06,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 1.25e-06,
    "output_cost_per_character_above_128k_tokens": 2.5e-06,
    "output_cost_per_token": 5e-06,
    "output_cost_per_token_above_128k_tokens": 1e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-1.5-pro-preview-0215": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 3.125e-05,
    "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
    "input_cost_per_character": 3.125e-07,
    "input_cost_per_character_above_128k_tokens": 6.25e-07,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125e-08,
    "input_cost_per_token_above_128k_tokens": 1.5625e-07,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 1.25e-06,
    "output_cost_per_character_above_128k_tokens": 2.5e-06,
    "output_cost_per_token": 3.125e-07,
    "output_cost_per_token_above_128k_tokens": 6.25e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gemini-1.5-pro-preview-0409": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 3.125e-05,
    "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
    "input_cost_per_character": 3.125e-07,
    "input_cost_per_character_above_128k_tokens": 6.25e-07,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125e-08,
    "input_cost_per_token_above_128k_tokens": 1.5625e-07,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 1.25e-06,
    "output_cost_per_character_above_128k_tokens": 2.5e-06,
    "output_cost_per_token": 3.125e-07,
    "output_cost_per_token_above_128k_tokens": 6.25e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_tool_choice": true
  },
  "gemini-1.5-pro-preview-0514": {
    "deprecation_date": "2025-09-29",
    "input_cost_per_audio_per_second": 3.125e-05,
    "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
    "input_cost_per_character": 3.125e-07,
    "input_cost_per_character_above_128k_tokens": 6.25e-07,
    "input_cost_per_image": 0.00032875,
    "input_cost_per_image_above_128k_tokens": 0.0006575,
    "input_cost_per_token": 7.8125e-08,
    "input_cost_per_token_above_128k_tokens": 1.5625e-07,
    "input_cost_per_video_per_second": 0.00032875,
    "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 1.25e-06,
    "output_cost_per_character_above_128k_tokens": 2.5e-06,
    "output_cost_per_token": 3.125e-07,
    "output_cost_per_token_above_128k_tokens": 6.25e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gemini-2.0-flash": {
    "cache_read_input_token_cost": 2.5e-08,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7e-07,
    "input_cost_per_token": 1e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-001": {
    "cache_read_input_token_cost": 3.75e-08,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 1.5e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 6e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-exp": {
    "cache_read_input_token_cost": 3.75e-08,
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 1.5e-07,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 6e-07,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-exp-image-generation": {
    "input_cost_per_token": 0.0,
    "litellm_provider": "gemini",
    "max_images_per_prompt": 3000,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "image_generation",
    "output_cost_per_image": 0.039,
    "output_cost_per_token": 0.0,
    "source": "https://ai.google.dev/pricing",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_vision": true
  },
  "gemini-2.0-flash-lite": {
    "cache_read_input_token_cost": 1.875e-08,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7.5e-08,
    "input_cost_per_token": 7.5e-08,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-lite-001": {
    "cache_read_input_token_cost": 1.875e-08,
    "deprecation_date": "2026-03-31",
    "input_cost_per_audio_token": 7.5e-08,
    "input_cost_per_token": 7.5e-08,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 50,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 3e-07,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-live-preview-04-09": {
    "cache_read_input_token_cost": 7.5e-08,
    "input_cost_per_audio_token": 3e-06,
    "input_cost_per_image": 3e-06,
    "input_cost_per_token": 5e-07,
    "input_cost_per_video_per_second": 3e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_audio_token": 1.2e-05,
    "output_cost_per_token": 2e-06,
    "rpm": 10,
    "source": "https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini#gemini-2-0-flash-live-preview-04-09",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini-2.0-flash-preview-image-generation": {
    "cache_read_input_token_cost": 2.5e-08,
    "deprecation_date": "2025-11-14",
    "input_cost_per_audio_token": 7e-07,
    "input_cost_per_token": 1e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "source": "https://ai.google.dev/pricing#2_0flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-thinking-exp": {
    "cache_read_input_token_cost": 0.0,
    "deprecation_date": "2025-12-02",
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-flash-thinking-exp-01-21": {
    "cache_read_input_token_cost": 0.0,
    "deprecation_date": "2025-12-02",
    "input_cost_per_audio_per_second": 0,
    "input_cost_per_audio_per_second_above_128k_tokens": 0,
    "input_cost_per_character": 0,
    "input_cost_per_character_above_128k_tokens": 0,
    "input_cost_per_image": 0,
    "input_cost_per_image_above_128k_tokens": 0,
    "input_cost_per_token": 0,
    "input_cost_per_token_above_128k_tokens": 0,
    "input_cost_per_video_per_second": 0,
    "input_cost_per_video_per_second_above_128k_tokens": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_character_above_128k_tokens": 0,
    "output_cost_per_token": 0,
    "output_cost_per_token_above_128k_tokens": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.0-pro-exp-02-05": {
    "cache_read_input_token_cost": 3.125e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 2097152,
    "max_output_tokens": 8192,
    "max_pdf_size_mb": 30,
    "max_tokens": 8192,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-computer-use-preview-10-2025": {
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_images_per_prompt": 3000,
    "max_input_tokens": 128000,
    "max_output_tokens": 64000,
    "max_tokens": 64000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use",
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_computer_use": true,
    "supports_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-2.5-flash": {
    "cache_read_input_token_cost": 3e-08,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 2.5e-06,
    "output_cost_per_token": 2.5e-06,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-image": {
    "cache_read_input_token_cost": 3e-08,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 32768,
    "max_output_tokens": 32768,
    "max_pdf_size_mb": 30,
    "max_tokens": 32768,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "image_generation",
    "output_cost_per_image": 0.039,
    "output_cost_per_image_token": 3e-05,
    "output_cost_per_reasoning_token": 2.5e-06,
    "output_cost_per_token": 2.5e-06,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash-image",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": false,
    "tpm": 8000000
  },
  "gemini-2.5-flash-image-preview": {
    "cache_read_input_token_cost": 7.5e-08,
    "deprecation_date": "2026-01-15",
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_image_token": 3e-07,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "image_generation",
    "output_cost_per_image": 0.039,
    "output_cost_per_image_token": 3e-05,
    "output_cost_per_reasoning_token": 3e-05,
    "output_cost_per_token": 3e-05,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  },
  "gemini-2.5-flash-lite": {
    "cache_read_input_token_cost": 1e-08,
    "input_cost_per_audio_token": 3e-07,
    "input_cost_per_token": 1e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4e-07,
    "output_cost_per_token": 4e-07,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-lite-preview-06-17": {
    "cache_read_input_token_cost": 2.5e-08,
    "deprecation_date": "2025-11-18",
    "input_cost_per_audio_token": 5e-07,
    "input_cost_per_token": 1e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4e-07,
    "output_cost_per_token": 4e-07,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-lite-preview-09-2025": {
    "cache_read_input_token_cost": 1e-08,
    "input_cost_per_audio_token": 3e-07,
    "input_cost_per_token": 1e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4e-07,
    "output_cost_per_token": 4e-07,
    "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-native-audio-latest": {
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2.5e-06,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true
  },
  "gemini-2.5-flash-native-audio-preview-09-2025": {
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2.5e-06,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true
  },
  "gemini-2.5-flash-native-audio-preview-12-2025": {
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "gemini",
    "max_input_tokens": 1048576,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_token": 2.5e-06,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true
  },
  "gemini-2.5-flash-preview-04-17": {
    "cache_read_input_token_cost": 3.75e-08,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 1.5e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 3.5e-06,
    "output_cost_per_token": 6e-07,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-preview-05-20": {
    "cache_read_input_token_cost": 7.5e-08,
    "deprecation_date": "2025-11-18",
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 2.5e-06,
    "output_cost_per_token": 2.5e-06,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-preview-09-2025": {
    "cache_read_input_token_cost": 7.5e-08,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 2.5e-06,
    "output_cost_per_token": 2.5e-06,
    "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-flash-preview-tts": {
    "input_cost_per_token": 3e-07,
    "litellm_provider": "gemini",
    "mode": "audio_speech",
    "output_cost_per_token": 2.5e-06,
    "source": "https://ai.google.dev/pricing",
    "supported_endpoints": [
      "/v1/audio/speech"
    ]
  },
  "gemini-2.5-pro": {
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_above_200k_tokens": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-exp-03-25": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_above_200k_tokens": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-preview-03-25": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_above_200k_tokens": 2.5e-07,
    "deprecation_date": "2025-12-02",
    "input_cost_per_audio_token": 1.25e-06,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-preview-05-06": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_above_200k_tokens": 2.5e-07,
    "deprecation_date": "2025-12-02",
    "input_cost_per_audio_token": 1.25e-06,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supported_regions": [
      "global"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-preview-06-05": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_above_200k_tokens": 2.5e-07,
    "input_cost_per_audio_token": 1.25e-06,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-2.5-pro-preview-tts": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_above_200k_tokens": 2.5e-07,
    "input_cost_per_audio_token": 7e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
    "supported_modalities": [
      "text"
    ],
    "supported_output_modalities": [
      "audio"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3-flash": {
    "cache_read_input_token_cost": 5e-08,
    "cache_read_input_token_cost_priority": 9e-08,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_audio_token_priority": 1.8e-06,
    "input_cost_per_token": 5e-07,
    "input_cost_per_token_priority": 9e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 3e-06,
    "output_cost_per_token": 3e-06,
    "output_cost_per_token_priority": 5.4e-06,
    "source": "https://ai.google.dev/pricing/gemini-3",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3-flash-preview": {
    "cache_read_input_token_cost": 5e-08,
    "cache_read_input_token_cost_priority": 9e-08,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_audio_token_priority": 1.8e-06,
    "input_cost_per_token": 5e-07,
    "input_cost_per_token_priority": 9e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 3e-06,
    "output_cost_per_token": 3e-06,
    "output_cost_per_token_priority": 5.4e-06,
    "source": "https://ai.google.dev/pricing/gemini-3",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3-pro-image-preview": {
    "input_cost_per_image": 0.0011,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 65536,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "image_generation",
    "output_cost_per_image": 0.134,
    "output_cost_per_image_token": 0.00012,
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_batches": 6e-06,
    "source": "https://ai.google.dev/gemini-api/docs/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3-pro-preview": {
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "cache_read_input_token_cost_above_200k_tokens_priority": 7.2e-07,
    "cache_read_input_token_cost_priority": 3.6e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_above_200k_tokens_priority": 7.2e-06,
    "input_cost_per_token_batches": 1e-06,
    "input_cost_per_token_priority": 3.6e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_above_200k_tokens_priority": 3.24e-05,
    "output_cost_per_token_batches": 6e-06,
    "output_cost_per_token_priority": 2.16e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3.1-flash-image": {
    "input_cost_per_image": 0.00056,
    "input_cost_per_token": 5e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 65536,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "image_generation",
    "output_cost_per_image": 0.0672,
    "output_cost_per_image_token": 6e-05,
    "output_cost_per_token": 3e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#gemini-models",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3.1-flash-image-preview": {
    "input_cost_per_image": 0.00056,
    "input_cost_per_token": 5e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 65536,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "image_generation",
    "output_cost_per_image": 0.0672,
    "output_cost_per_image_token": 6e-05,
    "output_cost_per_token": 3e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#gemini-models",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3.1-pro-high": {
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "cache_read_input_token_cost_above_200k_tokens_priority": 7.2e-07,
    "cache_read_input_token_cost_priority": 3.6e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_above_200k_tokens_priority": 7.2e-06,
    "input_cost_per_token_batches": 1e-06,
    "input_cost_per_token_priority": 3.6e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_image": 0.00012,
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_above_200k_tokens_priority": 3.24e-05,
    "output_cost_per_token_batches": 6e-06,
    "output_cost_per_token_priority": 2.16e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#gemini-models",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3.1-pro-low": {
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "cache_read_input_token_cost_above_200k_tokens_priority": 7.2e-07,
    "cache_read_input_token_cost_priority": 3.6e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_above_200k_tokens_priority": 7.2e-06,
    "input_cost_per_token_batches": 1e-06,
    "input_cost_per_token_priority": 3.6e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_image": 0.00012,
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_above_200k_tokens_priority": 3.24e-05,
    "output_cost_per_token_batches": 6e-06,
    "output_cost_per_token_priority": 2.16e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#gemini-models",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3.1-pro-preview": {
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "cache_read_input_token_cost_above_200k_tokens_priority": 7.2e-07,
    "cache_read_input_token_cost_priority": 3.6e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_above_200k_tokens_priority": 7.2e-06,
    "input_cost_per_token_batches": 1e-06,
    "input_cost_per_token_priority": 3.6e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_image": 0.00012,
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_above_200k_tokens_priority": 3.24e-05,
    "output_cost_per_token_batches": 6e-06,
    "output_cost_per_token_priority": 2.16e-05,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#gemini-models",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-3.1-pro-preview-customtools": {
    "cache_creation_input_token_cost_above_200k_tokens": 2.5e-07,
    "cache_read_input_token_cost": 2e-07,
    "cache_read_input_token_cost_above_200k_tokens": 4e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_above_200k_tokens": 4e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65536,
    "max_pdf_size_mb": 30,
    "max_tokens": 65536,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_image": 0.00012,
    "output_cost_per_token": 1.2e-05,
    "output_cost_per_token_above_200k_tokens": 1.8e-05,
    "output_cost_per_token_batches": 6e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#gemini-models",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-embedding-001": {
    "input_cost_per_token": 1.5e-07,
    "litellm_provider": "vertex_ai-embedding-models",
    "max_input_tokens": 2048,
    "max_tokens": 2048,
    "mode": "embedding",
    "output_cost_per_token": 0,
    "output_vector_size": 3072,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
  },
  "gemini-exp-1206": {
    "cache_read_input_token_cost": 3e-08,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 2.5e-06,
    "output_cost_per_token": 2.5e-06,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  },
  "gemini-flash-experimental": {
    "input_cost_per_character": 0,
    "input_cost_per_token": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-flash-latest": {
    "cache_read_input_token_cost": 3e-08,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 2.5e-06,
    "output_cost_per_token": 2.5e-06,
    "rpm": 100000,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 8000000
  },
  "gemini-flash-lite-latest": {
    "cache_read_input_token_cost": 1e-08,
    "input_cost_per_audio_token": 3e-07,
    "input_cost_per_token": 1e-07,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_reasoning_token": 4e-07,
    "output_cost_per_token": 4e-07,
    "rpm": 15,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 250000
  },
  "gemini-live-2.5-flash-preview-native-audio-09-2025": {
    "cache_read_input_token_cost": 7.5e-08,
    "input_cost_per_audio_token": 3e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_audio_token": 1.2e-05,
    "output_cost_per_token": 2e-06,
    "source": "https://ai.google.dev/gemini-api/docs/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gemini-pro": {
    "input_cost_per_character": 1.25e-07,
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "input_cost_per_video_per_second": 0.002,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 32760,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 3.75e-07,
    "output_cost_per_token": 1.5e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-pro-experimental": {
    "input_cost_per_character": 0,
    "input_cost_per_token": 0,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1000000,
    "max_output_tokens": 8192,
    "max_tokens": 8192,
    "mode": "chat",
    "output_cost_per_character": 0,
    "output_cost_per_token": 0,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
    "supports_function_calling": false,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true
  },
  "gemini-pro-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_above_200k_tokens": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_above_200k_tokens": 2.5e-06,
    "litellm_provider": "gemini",
    "max_audio_length_hours": 8.4,
    "max_audio_per_prompt": 1,
    "max_images_per_prompt": 3000,
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_pdf_size_mb": 30,
    "max_tokens": 65535,
    "max_video_length": 1,
    "max_videos_per_prompt": 10,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_above_200k_tokens": 1.5e-05,
    "rpm": 2000,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio",
      "video"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_input": true,
    "supports_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_video_input": true,
    "supports_vision": true,
    "supports_web_search": true,
    "tpm": 800000
  },
  "gemini-pro-vision": {
    "input_cost_per_image": 0.0025,
    "input_cost_per_token": 5e-07,
    "litellm_provider": "vertex_ai-vision-models",
    "max_images_per_prompt": 16,
    "max_input_tokens": 16384,
    "max_output_tokens": 2048,
    "max_tokens": 2048,
    "max_video_length": 2,
    "max_videos_per_prompt": 1,
    "mode": "chat",
    "output_cost_per_token": 1.5e-06,
    "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gemini-robotics-er-1.5-preview": {
    "cache_read_input_token_cost": 0,
    "input_cost_per_audio_token": 1e-06,
    "input_cost_per_token": 3e-07,
    "litellm_provider": "vertex_ai-language-models",
    "max_input_tokens": 1048576,
    "max_output_tokens": 65535,
    "max_tokens": 65535,
    "mode": "chat",
    "output_cost_per_reasoning_token": 2.5e-06,
    "output_cost_per_token": 2.5e-06,
    "source": "https://ai.google.dev/gemini-api/docs/models#gemini-robotics-er-1-5-preview",
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/completions"
    ],
    "supported_modalities": [
      "text",
      "image",
      "video",
      "audio"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_audio_output": false,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_url_context": true,
    "supports_vision": true
  },
  "gpt-3.5-turbo": {
    "input_cost_per_token": 5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.5e-06,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-3.5-turbo-0125": {
    "input_cost_per_token": 5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.5e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-3.5-turbo-0301": {
    "input_cost_per_token": 1.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-3.5-turbo-0613": {
    "input_cost_per_token": 1.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-3.5-turbo-1106": {
    "deprecation_date": "2026-09-28",
    "input_cost_per_token": 1e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-3.5-turbo-16k": {
    "input_cost_per_token": 3e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 4e-06,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-3.5-turbo-16k-0613": {
    "input_cost_per_token": 3e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 4e-06,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-3.5-turbo-instruct": {
    "input_cost_per_token": 1.5e-06,
    "litellm_provider": "text-completion-openai",
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "completion",
    "output_cost_per_token": 2e-06
  },
  "gpt-3.5-turbo-instruct-0914": {
    "input_cost_per_token": 1.5e-06,
    "litellm_provider": "text-completion-openai",
    "max_input_tokens": 8192,
    "max_output_tokens": 4097,
    "max_tokens": 4097,
    "mode": "completion",
    "output_cost_per_token": 2e-06
  },
  "gpt-4": {
    "input_cost_per_token": 3e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6e-05,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-0125-preview": {
    "deprecation_date": "2026-03-26",
    "input_cost_per_token": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-0314": {
    "input_cost_per_token": 3e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6e-05,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-0613": {
    "deprecation_date": "2025-06-06",
    "input_cost_per_token": 3e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 6e-05,
    "supports_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-1106-preview": {
    "deprecation_date": "2026-03-26",
    "input_cost_per_token": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-1106-vision-preview": {
    "deprecation_date": "2024-12-06",
    "input_cost_per_token": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3e-05,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4-32k": {
    "input_cost_per_token": 6e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00012,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-32k-0314": {
    "input_cost_per_token": 6e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00012,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-32k-0613": {
    "input_cost_per_token": 6e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 0.00012,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-turbo": {
    "input_cost_per_token": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4-turbo-2024-04-09": {
    "input_cost_per_token": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4-turbo-preview": {
    "input_cost_per_token": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4-vision-preview": {
    "deprecation_date": "2024-12-06",
    "input_cost_per_token": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 3e-05,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.1": {
    "cache_read_input_token_cost": 5e-07,
    "cache_read_input_token_cost_priority": 8.75e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_batches": 1e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 8e-06,
    "output_cost_per_token_batches": 4e-06,
    "output_cost_per_token_priority": 1.4e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.1-2025-04-14": {
    "cache_read_input_token_cost": 5e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 8e-06,
    "output_cost_per_token_batches": 4e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.1-mini": {
    "cache_read_input_token_cost": 1e-07,
    "cache_read_input_token_cost_priority": 1.75e-07,
    "input_cost_per_token": 4e-07,
    "input_cost_per_token_batches": 2e-07,
    "input_cost_per_token_priority": 7e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 1.6e-06,
    "output_cost_per_token_batches": 8e-07,
    "output_cost_per_token_priority": 2.8e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.1-mini-2025-04-14": {
    "cache_read_input_token_cost": 1e-07,
    "input_cost_per_token": 4e-07,
    "input_cost_per_token_batches": 2e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 1.6e-06,
    "output_cost_per_token_batches": 8e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.1-nano": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_priority": 5e-08,
    "input_cost_per_token": 1e-07,
    "input_cost_per_token_batches": 5e-08,
    "input_cost_per_token_priority": 2e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "output_cost_per_token_batches": 2e-07,
    "output_cost_per_token_priority": 8e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.1-nano-2025-04-14": {
    "cache_read_input_token_cost": 2.5e-08,
    "input_cost_per_token": 1e-07,
    "input_cost_per_token_batches": 5e-08,
    "litellm_provider": "openai",
    "max_input_tokens": 1047576,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "output_cost_per_token_batches": 2e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.5-preview": {
    "cache_read_input_token_cost": 3.75e-05,
    "input_cost_per_token": 7.5e-05,
    "input_cost_per_token_batches": 3.75e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_batches": 7.5e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4.5-preview-2025-02-27": {
    "cache_read_input_token_cost": 3.75e-05,
    "deprecation_date": "2025-07-14",
    "input_cost_per_token": 7.5e-05,
    "input_cost_per_token_batches": 3.75e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 0.00015,
    "output_cost_per_token_batches": 7.5e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o": {
    "cache_read_input_token_cost": 1.25e-06,
    "cache_read_input_token_cost_priority": 2.125e-06,
    "input_cost_per_token": 2.5e-06,
    "input_cost_per_token_batches": 1.25e-06,
    "input_cost_per_token_priority": 4.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_batches": 5e-06,
    "output_cost_per_token_priority": 1.7e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-2024-05-13": {
    "input_cost_per_token": 5e-06,
    "input_cost_per_token_batches": 2.5e-06,
    "input_cost_per_token_priority": 8.75e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_token": 1.5e-05,
    "output_cost_per_token_batches": 7.5e-06,
    "output_cost_per_token_priority": 2.625e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-2024-08-06": {
    "cache_read_input_token_cost": 1.25e-06,
    "input_cost_per_token": 2.5e-06,
    "input_cost_per_token_batches": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_batches": 5e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-2024-11-20": {
    "cache_read_input_token_cost": 1.25e-06,
    "input_cost_per_token": 2.5e-06,
    "input_cost_per_token_batches": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_batches": 5e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-audio-preview": {
    "input_cost_per_audio_token": 4e-05,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 8e-05,
    "output_cost_per_token": 1e-05,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-audio-preview-2024-10-01": {
    "input_cost_per_audio_token": 4e-05,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 8e-05,
    "output_cost_per_token": 1e-05,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 4e-05,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 8e-05,
    "output_cost_per_token": 1e-05,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-audio-preview-2025-06-03": {
    "input_cost_per_audio_token": 4e-05,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 8e-05,
    "output_cost_per_token": 1e-05,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini": {
    "cache_read_input_token_cost": 7.5e-08,
    "cache_read_input_token_cost_priority": 1.25e-07,
    "input_cost_per_token": 1.5e-07,
    "input_cost_per_token_batches": 7.5e-08,
    "input_cost_per_token_priority": 2.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6e-07,
    "output_cost_per_token_batches": 3e-07,
    "output_cost_per_token_priority": 1e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-mini-2024-07-18": {
    "cache_read_input_token_cost": 7.5e-08,
    "input_cost_per_token": 1.5e-07,
    "input_cost_per_token_batches": 7.5e-08,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6e-07,
    "output_cost_per_token_batches": 3e-07,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.03,
      "search_context_size_low": 0.025,
      "search_context_size_medium": 0.0275
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-mini-audio-preview": {
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_token": 1.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 6e-07,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini-audio-preview-2024-12-17": {
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_token": 1.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 6e-07,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini-realtime-preview": {
    "cache_creation_input_audio_token_cost": 3e-07,
    "cache_read_input_token_cost": 3e-07,
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 2.4e-06,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini-realtime-preview-2024-12-17": {
    "cache_creation_input_audio_token_cost": 3e-07,
    "cache_read_input_token_cost": 3e-07,
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 2.4e-06,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-mini-search-preview": {
    "cache_read_input_token_cost": 7.5e-08,
    "input_cost_per_token": 1.5e-07,
    "input_cost_per_token_batches": 7.5e-08,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6e-07,
    "output_cost_per_token_batches": 3e-07,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.03,
      "search_context_size_low": 0.025,
      "search_context_size_medium": 0.0275
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-4o-mini-search-preview-2025-03-11": {
    "cache_read_input_token_cost": 7.5e-08,
    "input_cost_per_token": 1.5e-07,
    "input_cost_per_token_batches": 7.5e-08,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 6e-07,
    "output_cost_per_token_batches": 3e-07,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-mini-transcribe": {
    "input_cost_per_audio_token": 3e-06,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "mode": "audio_transcription",
    "output_cost_per_token": 5e-06,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ]
  },
  "gpt-4o-mini-transcribe-2025-03-20": {
    "input_cost_per_audio_token": 3e-06,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "mode": "audio_transcription",
    "output_cost_per_token": 5e-06,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ]
  },
  "gpt-4o-mini-transcribe-2025-12-15": {
    "input_cost_per_audio_token": 3e-06,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "mode": "audio_transcription",
    "output_cost_per_token": 5e-06,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ]
  },
  "gpt-4o-mini-tts": {
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "mode": "audio_speech",
    "output_cost_per_audio_token": 1.2e-05,
    "output_cost_per_second": 0.00025,
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/audio/speech"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "audio"
    ]
  },
  "gpt-4o-mini-tts-2025-03-20": {
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "mode": "audio_speech",
    "output_cost_per_audio_token": 1.2e-05,
    "output_cost_per_second": 0.00025,
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/audio/speech"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "audio"
    ]
  },
  "gpt-4o-mini-tts-2025-12-15": {
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "mode": "audio_speech",
    "output_cost_per_audio_token": 1.2e-05,
    "output_cost_per_second": 0.00025,
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/audio/speech"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "audio"
    ]
  },
  "gpt-4o-realtime-preview": {
    "cache_read_input_token_cost": 2.5e-06,
    "input_cost_per_audio_token": 4e-05,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 8e-05,
    "output_cost_per_token": 2e-05,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-realtime-preview-2024-10-01": {
    "cache_creation_input_audio_token_cost": 2e-05,
    "cache_read_input_token_cost": 2.5e-06,
    "input_cost_per_audio_token": 0.0001,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 0.0002,
    "output_cost_per_token": 2e-05,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-realtime-preview-2024-12-17": {
    "cache_read_input_token_cost": 2.5e-06,
    "input_cost_per_audio_token": 4e-05,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 8e-05,
    "output_cost_per_token": 2e-05,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-realtime-preview-2025-06-03": {
    "cache_read_input_token_cost": 2.5e-06,
    "input_cost_per_audio_token": 4e-05,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 8e-05,
    "output_cost_per_token": 2e-05,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-4o-search-preview": {
    "cache_read_input_token_cost": 1.25e-06,
    "input_cost_per_token": 2.5e-06,
    "input_cost_per_token_batches": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_batches": 5e-06,
    "search_context_cost_per_query": {
      "search_context_size_high": 0.05,
      "search_context_size_low": 0.03,
      "search_context_size_medium": 0.035
    },
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-4o-search-preview-2025-03-11": {
    "cache_read_input_token_cost": 1.25e-06,
    "input_cost_per_token": 2.5e-06,
    "input_cost_per_token_batches": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_batches": 5e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-4o-transcribe": {
    "input_cost_per_audio_token": 6e-06,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "mode": "audio_transcription",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ]
  },
  "gpt-4o-transcribe-diarize": {
    "input_cost_per_audio_token": 6e-06,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 16000,
    "max_output_tokens": 2000,
    "mode": "audio_transcription",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/audio/transcriptions"
    ]
  },
  "gpt-5": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_flex": 6.25e-08,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_flex": 6.25e-07,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_flex": 5e-06,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-2025-08-07": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_flex": 6.25e-08,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_flex": 6.25e-07,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_flex": 5e-06,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-chat": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5-chat-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_flex": 1.25e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_flex": 1.25e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_flex": 1e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-mini-2025-08-07": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_flex": 1.25e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_flex": 1.25e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_flex": 1e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-nano": {
    "cache_read_input_token_cost": 5e-09,
    "cache_read_input_token_cost_flex": 2.5e-09,
    "input_cost_per_token": 5e-08,
    "input_cost_per_token_flex": 2.5e-08,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "output_cost_per_token_flex": 2e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-nano-2025-08-07": {
    "cache_read_input_token_cost": 5e-09,
    "cache_read_input_token_cost_flex": 2.5e-09,
    "input_cost_per_token": 5e-08,
    "input_cost_per_token_flex": 2.5e-08,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 4e-07,
    "output_cost_per_token_flex": 2e-07,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5-pro": {
    "input_cost_per_token": 1.5e-05,
    "input_cost_per_token_batches": 7.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 272000,
    "max_tokens": 272000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "output_cost_per_token_batches": 6e-05,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-pro-2025-10-06": {
    "input_cost_per_token": 1.5e-05,
    "input_cost_per_token_batches": 7.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 272000,
    "max_tokens": 272000,
    "mode": "responses",
    "output_cost_per_token": 0.00012,
    "output_cost_per_token_batches": 6e-05,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-search-api": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5-search-api-2025-10-14": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5.1": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-2025-11-13": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-chat-latest": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": false,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": false,
    "supports_vision": true
  },
  "gpt-5.1-codex": {
    "cache_read_input_token_cost": 1.25e-07,
    "cache_read_input_token_cost_priority": 2.5e-07,
    "input_cost_per_token": 1.25e-06,
    "input_cost_per_token_priority": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "output_cost_per_token_priority": 2e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex-max": {
    "cache_read_input_token_cost": 1.25e-07,
    "input_cost_per_token": 1.25e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.1-codex-mini": {
    "cache_read_input_token_cost": 2.5e-08,
    "cache_read_input_token_cost_priority": 4.5e-08,
    "input_cost_per_token": 2.5e-07,
    "input_cost_per_token_priority": 4.5e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 2e-06,
    "output_cost_per_token_priority": 3.6e-06,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-2025-12-11": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text",
      "image"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-chat-latest": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-codex": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.2-pro": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5.2-pro-2025-12-11": {
    "input_cost_per_token": 2.1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 0.000168,
    "supported_endpoints": [
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true,
    "supports_web_search": true
  },
  "gpt-5.3-codex": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-5.3-codex-spark": {
    "cache_read_input_token_cost": 1.75e-07,
    "cache_read_input_token_cost_priority": 3.5e-07,
    "input_cost_per_token": 1.75e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 272000,
    "max_output_tokens": 128000,
    "max_tokens": 128000,
    "mode": "responses",
    "output_cost_per_token": 1.4e-05,
    "output_cost_per_token_priority": 2.8e-05,
    "supported_endpoints": [
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": false,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "gpt-audio": {
    "input_cost_per_audio_token": 3.2e-05,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 6.4e-05,
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-1.5": {
    "input_cost_per_audio_token": 3.2e-05,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 6.4e-05,
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-2025-08-28": {
    "input_cost_per_audio_token": 3.2e-05,
    "input_cost_per_token": 2.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 6.4e-05,
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-mini": {
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 2.4e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-mini-2025-10-06": {
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 2.4e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-audio-mini-2025-12-15": {
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "max_tokens": 16384,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 2.4e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/responses",
      "/v1/realtime",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_prompt_caching": false,
    "supports_reasoning": false,
    "supports_response_schema": false,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "gpt-image-1": {
    "cache_read_input_image_token_cost": 2.5e-06,
    "cache_read_input_token_cost": 1.25e-06,
    "input_cost_per_image_token": 1e-05,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "openai",
    "mode": "image_generation",
    "output_cost_per_image_token": 4e-05,
    "supported_endpoints": [
      "/v1/images/generations",
      "/v1/images/edits"
    ]
  },
  "gpt-image-1-mini": {
    "cache_read_input_image_token_cost": 2.5e-07,
    "cache_read_input_token_cost": 2e-07,
    "input_cost_per_image_token": 2.5e-06,
    "input_cost_per_token": 2e-06,
    "litellm_provider": "openai",
    "mode": "image_generation",
    "output_cost_per_image_token": 8e-06,
    "supported_endpoints": [
      "/v1/images/generations",
      "/v1/images/edits"
    ]
  },
  "gpt-image-1.5": {
    "cache_read_input_image_token_cost": 2e-06,
    "cache_read_input_token_cost": 1.25e-06,
    "input_cost_per_image_token": 8e-06,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "openai",
    "mode": "image_generation",
    "output_cost_per_image_token": 3.2e-05,
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "supports_pdf_input": true,
    "supports_vision": true
  },
  "gpt-image-1.5-2025-12-16": {
    "cache_read_input_image_token_cost": 2e-06,
    "cache_read_input_token_cost": 1.25e-06,
    "input_cost_per_image_token": 8e-06,
    "input_cost_per_token": 5e-06,
    "litellm_provider": "openai",
    "mode": "image_generation",
    "output_cost_per_image_token": 3.2e-05,
    "output_cost_per_token": 1e-05,
    "supported_endpoints": [
      "/v1/images/generations"
    ],
    "supports_pdf_input": true,
    "supports_vision": true
  },
  "gpt-realtime": {
    "cache_creation_input_audio_token_cost": 4e-07,
    "cache_read_input_token_cost": 4e-07,
    "input_cost_per_audio_token": 3.2e-05,
    "input_cost_per_image": 5e-06,
    "input_cost_per_token": 4e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 32000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 6.4e-05,
    "output_cost_per_token": 1.6e-05,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-realtime-1.5": {
    "cache_creation_input_audio_token_cost": 4e-07,
    "cache_read_input_token_cost": 4e-07,
    "input_cost_per_audio_token": 3.2e-05,
    "input_cost_per_image": 5e-06,
    "input_cost_per_token": 4e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 32000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 6.4e-05,
    "output_cost_per_token": 1.6e-05,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-realtime-2025-08-28": {
    "cache_creation_input_audio_token_cost": 4e-07,
    "cache_read_input_token_cost": 4e-07,
    "input_cost_per_audio_token": 3.2e-05,
    "input_cost_per_image": 5e-06,
    "input_cost_per_token": 4e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 32000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 6.4e-05,
    "output_cost_per_token": 1.6e-05,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-realtime-mini": {
    "cache_creation_input_audio_token_cost": 3e-07,
    "cache_read_input_audio_token_cost": 3e-07,
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 2.4e-06,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-realtime-mini-2025-10-06": {
    "cache_creation_input_audio_token_cost": 3e-07,
    "cache_read_input_audio_token_cost": 3e-07,
    "cache_read_input_token_cost": 6e-08,
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_image": 8e-07,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 2.4e-06,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "gpt-realtime-mini-2025-12-15": {
    "cache_creation_input_audio_token_cost": 3e-07,
    "cache_read_input_audio_token_cost": 3e-07,
    "cache_read_input_token_cost": 6e-08,
    "input_cost_per_audio_token": 1e-05,
    "input_cost_per_image": 8e-07,
    "input_cost_per_token": 6e-07,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "max_tokens": 4096,
    "mode": "chat",
    "output_cost_per_audio_token": 2e-05,
    "output_cost_per_token": 2.4e-06,
    "supported_endpoints": [
      "/v1/realtime"
    ],
    "supported_modalities": [
      "text",
      "image",
      "audio"
    ],
    "supported_output_modalities": [
      "text",
      "audio"
    ],
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_system_messages": true,
    "supports_tool_choice": true
  },
  "o1-2024-12-17": {
    "cache_read_input_token_cost": 7.5e-06,
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 6e-05,
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o1-mini": {
    "cache_read_input_token_cost": 5.5e-07,
    "input_cost_per_token": 1.1e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 4.4e-06,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_vision": true
  },
  "o1-mini-2024-09-12": {
    "cache_read_input_token_cost": 1.5e-06,
    "deprecation_date": "2025-10-27",
    "input_cost_per_token": 3e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "max_tokens": 65536,
    "mode": "chat",
    "output_cost_per_token": 1.2e-05,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true
  },
  "o1-preview": {
    "cache_read_input_token_cost": 7.5e-06,
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 6e-05,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true
  },
  "o1-preview-2024-09-12": {
    "cache_read_input_token_cost": 7.5e-06,
    "input_cost_per_token": 1.5e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "max_tokens": 32768,
    "mode": "chat",
    "output_cost_per_token": 6e-05,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_vision": true
  },
  "o1-pro": {
    "input_cost_per_token": 0.00015,
    "input_cost_per_token_batches": 7.5e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.0006,
    "output_cost_per_token_batches": 0.0003,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o1-pro-2025-03-19": {
    "input_cost_per_token": 0.00015,
    "input_cost_per_token_batches": 7.5e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 0.0006,
    "output_cost_per_token_batches": 0.0003,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": false,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3": {
    "cache_read_input_token_cost": 5e-07,
    "cache_read_input_token_cost_flex": 2.5e-07,
    "cache_read_input_token_cost_priority": 8.75e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_flex": 1e-06,
    "input_cost_per_token_priority": 3.5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 8e-06,
    "output_cost_per_token_flex": 4e-06,
    "output_cost_per_token_priority": 1.4e-05,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3-2025-04-16": {
    "cache_read_input_token_cost": 5e-07,
    "input_cost_per_token": 2e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 8e-06,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/chat/completions",
      "/v1/completions",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3-deep-research": {
    "cache_read_input_token_cost": 2.5e-06,
    "input_cost_per_token": 1e-05,
    "input_cost_per_token_batches": 5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 4e-05,
    "output_cost_per_token_batches": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3-deep-research-2025-06-26": {
    "cache_read_input_token_cost": 2.5e-06,
    "input_cost_per_token": 1e-05,
    "input_cost_per_token_batches": 5e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 4e-05,
    "output_cost_per_token_batches": 2e-05,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3-mini": {
    "cache_read_input_token_cost": 5.5e-07,
    "input_cost_per_token": 1.1e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 4.4e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "o3-mini-2025-01-31": {
    "cache_read_input_token_cost": 5.5e-07,
    "input_cost_per_token": 1.1e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 4.4e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": false
  },
  "o3-pro": {
    "input_cost_per_token": 2e-05,
    "input_cost_per_token_batches": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 8e-05,
    "output_cost_per_token_batches": 4e-05,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o3-pro-2025-06-10": {
    "input_cost_per_token": 2e-05,
    "input_cost_per_token_batches": 1e-05,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 8e-05,
    "output_cost_per_token_batches": 4e-05,
    "supported_endpoints": [
      "/v1/responses",
      "/v1/batch"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o4-mini": {
    "cache_read_input_token_cost": 2.75e-07,
    "cache_read_input_token_cost_flex": 1.375e-07,
    "cache_read_input_token_cost_priority": 5e-07,
    "input_cost_per_token": 1.1e-06,
    "input_cost_per_token_flex": 5.5e-07,
    "input_cost_per_token_priority": 2e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 4.4e-06,
    "output_cost_per_token_flex": 2.2e-06,
    "output_cost_per_token_priority": 8e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o4-mini-2025-04-16": {
    "cache_read_input_token_cost": 2.75e-07,
    "input_cost_per_token": 1.1e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "chat",
    "output_cost_per_token": 4.4e-06,
    "supports_function_calling": true,
    "supports_parallel_function_calling": false,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_reasoning": true,
    "supports_response_schema": true,
    "supports_service_tier": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o4-mini-deep-research": {
    "cache_read_input_token_cost": 5e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 8e-06,
    "output_cost_per_token_batches": 4e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  },
  "o4-mini-deep-research-2025-06-26": {
    "cache_read_input_token_cost": 5e-07,
    "input_cost_per_token": 2e-06,
    "input_cost_per_token_batches": 1e-06,
    "litellm_provider": "openai",
    "max_input_tokens": 200000,
    "max_output_tokens": 100000,
    "max_tokens": 100000,
    "mode": "responses",
    "output_cost_per_token": 8e-06,
    "output_cost_per_token_batches": 4e-06,
    "supported_endpoints": [
      "/v1/chat/completions",
      "/v1/batch",
      "/v1/responses"
    ],
    "supported_modalities": [
      "text",
      "image"
    ],
    "supported_output_modalities": [
      "text"
    ],
    "supports_function_calling": true,
    "supports_native_streaming": true,
    "supports_parallel_function_calling": true,
    "supports_pdf_input": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_tool_choice": true,
    "supports_vision": true
  }
}
